<p>
    Test Phase is the final evaluation stage of the Composed Video Retrieval Challenge, where participants submit their models' predictions on an unseen test dataset. The performance in this phase will determine the final rankings on the leaderboard.

    Key Details:
    <ol type="1">
        <li>Blind Evaluation: Unlike the validation phase, the ground truth for the test dataset will not be released. Participants must submit their predicted results, which will be evaluated against hidden ground truth annotations.
        </li>
        <li>Submission Limits: The number of submissions per team may be restricted to ensure fair competition. Participants should carefully optimize their models before making final test submissions.
        </li>
        <li>Evaluation Metrics: The test phase will use the Recall@K metric, including R1, R5, R10, R50, meanR3, and meanR4, to assess retrieval accuracy comprehensively.
        </li>
        <li>Private Leaderboard: During the test phase, submissions will be evaluated on a private leaderboard, where only the final results will be used to determine the rankings.
        </li>
        <li>Final Model Selection: Participants are encouraged to submit their best-performing model from the validation phase, as test phase submissions will be considered final for ranking purposes.
        </li>
        <li>Fair Play & Compliance: Any attempt to manually label test data, use external datasets beyond the challenge guidelines, or engage in unfair practices will lead to disqualification.</li>
    </ol>
</p>
<p>
    At the end of the test phase, the final leaderboard will be announced, showcasing the top-performing models in the challenge. This is the ultimate test of how well a model can generalize to unseen compositional video retrieval scenarios. Good luck! ðŸš€
</p>
