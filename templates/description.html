<h3>Welcome to the Composed Video Retrieval (CoVR) challenge 2025!</h3>
<p>ðŸ˜Š
    <a href="">Dataset</a>
    |ðŸ’»
    <a href="">Github</a>
    |ðŸ“–
    <a href="">arXiv</a>
</p>


<h4>Task</h4>
<!-- <p>Complex Video Reasoning and Robustness Evaluation Suite (CVRR-ES) is a comprehensive benchmark designed  to assess the reasoning and robustness capabilities of Video Large Language Models (Video-LLMs) in real-world scenarios. Unlike existing video benchmarks that focus primarily on simple video comprehension, CVRR-ES evaluates models on their ability to handle intricate reasoning tasks and robustly respond to diverse user prompts across a range of realworld contexts. The benchmark comprises 11 diverse real-world video category dimensions, including multiple actions in a single video, fine-grained action understanding, partial actions, time order understanding, non-existent actions with existent scene depictions, non-existent actions with non-existent scene depictions, continuity and object instance count, unusual and physically anomalous activities, interpretation of social context, understanding of emotional context, and interpretation of visual context. </p> -->


<h4>Dataset</h4>
<!-- Overall, validation split consists of 2400 open-ended question-answer (QA) pairs spanning 214 unique videos. The average video duration is 22.3 seconds, with maximum and minimum durations of 183 and 2 seconds, respectively. -->


<h4>Challenge Phases</h4>
<ol type="1">
    <li>Validation Phase: Participants submit their model predictions on the validation dataset. Participants can choose to make submissions public or private during this phase and the number of submissions will not be limited.</li>
    <li>Test Phase: Participants submit their model predictions on the test dataset. The final evaluation and ranking will be based on the performance on this split. Submissions are limited in this phase.</li>
</ol>


<h4>Competition Rules</h4>
<ol type="1">
  <li>Submissions must be public in the test phase to be considered for the prize.</li>
  <li>Participants need to submit a technical report (PDF file).</li>
  <li>There must be no explicit human labelling on the test videos.</li>
  <li>Test and validation data must not be used for any kind of training (supervised or self-supervised). Any other dataset can be used for training, fine-tuning, or prompting.</li>
  <li>There are no restrictions on the model side.</li>
</ol>
<p>
    <strong>For more detailed challenge information, please refer to <a href="https://www.rohitg.xyz/VideoLLMsWorkshop/challenges.html">Competition Homepage</a>.</strong>
</p>
