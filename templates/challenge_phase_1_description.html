<p>
    During the Validation Phase, participants will have access to the validation dataset along with its ground truth annotations. This phase serves as an opportunity for participants to test, refine, and benchmark their models before proceeding to the final test phase.

    Key Details:
    <ol type="1">
        <li>Model Selection & Benchmarking: Participants are encouraged to use any open-source multi-modal model and compare their results against the provided baseline model. We also provide scripts to assist in processing predictions and evaluating results.</li>
        <li>Unlimited Submissions: There are no restrictions on the number of submissions during this phase. Participants can continuously refine their models and improve their retrieval performance by analyzing validation set results.</li>
        <li>Public vs. Private Submissions: Participants can choose to make their validation submissions public or private based on their preference.</li>
        <li>Evaluation & Feedback: Submissions will be evaluated using the Recall@K metric, providing feedback on retrieval accuracy. However, final rankings will not be based on validation resultsâ€”only test set performance will determine the final leaderboard standings.</li>
        <li>This phase is designed to help participants fine-tune their models, analyze performance trends, and prepare for the final Test Phase, where submissions will be evaluated on unseen data.</li>
    </ol>
</p>